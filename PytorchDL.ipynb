{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not there\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(0)\n",
    "torch.rand(2,2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU is available')\n",
    "    torch.cude.manual_seed_all(0)\n",
    "else:\n",
    "    print('GPU is not there')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.IntTensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 2x2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.from_numpy(np.array([1,2]))\n",
    "print(type(torch_tensor))\n",
    "np_array2 = np.ones((2,2), dtype=np.double)\n",
    "torch.from_numpy(np_array2)\n",
    "# print(type(torch.from_numpy(np_array2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch can use \n",
    "1. double\n",
    "2. float\n",
    "3. int64, int32, uint8 from numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''From torch to np''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor = torch.ones(2,2)\n",
    "torch_to_numpy = torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch_to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cpu = torch.ones(2,2)\n",
    "tensor_cpu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2)\n",
    "b = torch.zeros(2,2)\n",
    "# a.view(4)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = torch.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.div_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.zeros(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.mul(a, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2e56bd611584>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Sec 4 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       "[torch.IntTensor of size 2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      " 15\n",
      "[torch.DoubleTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import *\n",
    "x = Variable(torch.from_numpy(np.array([1,2], dtype=np.double)), requires_grad=True)\n",
    "y = 5 * (x+1)**2\n",
    "o = 0.5 * torch.sum(y)\n",
    "# print(o)\n",
    "o.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Sec 6 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = [i for i in range(11)]\n",
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values = [2*i+1 for i in x_values]\n",
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_values, dtype=np.float32).reshape(-1,1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__() # inherent nn.Module\n",
    "        # global\n",
    "        print('input_dim = {}, output_dim = {}'.format(input_dim, output_dim))\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim = 1, output_dim = 1\n",
      "epoch 1, loss 93.99771118164062\n",
      "epoch 2, loss 8.291688919067383\n",
      "epoch 3, loss 1.2939410209655762\n",
      "epoch 4, loss 0.7162611484527588\n",
      "epoch 5, loss 0.6623216271400452\n",
      "epoch 6, loss 0.6511784791946411\n",
      "epoch 7, loss 0.64360111951828\n",
      "epoch 8, loss 0.6363891363143921\n",
      "epoch 9, loss 0.6292809844017029\n",
      "epoch 10, loss 0.6222537755966187\n",
      "epoch 11, loss 0.6153053045272827\n",
      "epoch 12, loss 0.6084336638450623\n",
      "epoch 13, loss 0.6016395688056946\n",
      "epoch 14, loss 0.5949206948280334\n",
      "epoch 15, loss 0.5882776379585266\n",
      "epoch 16, loss 0.581708550453186\n",
      "epoch 17, loss 0.5752124190330505\n",
      "epoch 18, loss 0.5687894225120544\n",
      "epoch 19, loss 0.5624378323554993\n",
      "epoch 20, loss 0.5561570525169373\n",
      "epoch 21, loss 0.5499465465545654\n",
      "epoch 22, loss 0.5438055992126465\n",
      "epoch 23, loss 0.5377328395843506\n",
      "epoch 24, loss 0.5317280292510986\n",
      "epoch 25, loss 0.5257900953292847\n",
      "epoch 26, loss 0.5199187994003296\n",
      "epoch 27, loss 0.5141131281852722\n",
      "epoch 28, loss 0.508371889591217\n",
      "epoch 29, loss 0.5026953220367432\n",
      "epoch 30, loss 0.497081458568573\n",
      "epoch 31, loss 0.49153080582618713\n",
      "epoch 32, loss 0.4860420525074005\n",
      "epoch 33, loss 0.4806147515773773\n",
      "epoch 34, loss 0.4752475917339325\n",
      "epoch 35, loss 0.46994030475616455\n",
      "epoch 36, loss 0.464692622423172\n",
      "epoch 37, loss 0.45950356125831604\n",
      "epoch 38, loss 0.4543725252151489\n",
      "epoch 39, loss 0.44929835200309753\n",
      "epoch 40, loss 0.44428128004074097\n",
      "epoch 41, loss 0.4393198788166046\n",
      "epoch 42, loss 0.43441393971443176\n",
      "epoch 43, loss 0.4295633137226105\n",
      "epoch 44, loss 0.4247663617134094\n",
      "epoch 45, loss 0.4200230538845062\n",
      "epoch 46, loss 0.41533252596855164\n",
      "epoch 47, loss 0.4106946289539337\n",
      "epoch 48, loss 0.4061084985733032\n",
      "epoch 49, loss 0.4015737771987915\n",
      "epoch 50, loss 0.39708900451660156\n",
      "epoch 51, loss 0.3926549255847931\n",
      "epoch 52, loss 0.38827040791511536\n",
      "epoch 53, loss 0.3839346766471863\n",
      "epoch 54, loss 0.37964707612991333\n",
      "epoch 55, loss 0.37540769577026367\n",
      "epoch 56, loss 0.37121573090553284\n",
      "epoch 57, loss 0.3670700788497925\n",
      "epoch 58, loss 0.3629710376262665\n",
      "epoch 59, loss 0.3589181900024414\n",
      "epoch 60, loss 0.3549102544784546\n",
      "epoch 61, loss 0.3509468734264374\n",
      "epoch 62, loss 0.347027987241745\n",
      "epoch 63, loss 0.3431525230407715\n",
      "epoch 64, loss 0.3393205404281616\n",
      "epoch 65, loss 0.3355315327644348\n",
      "epoch 66, loss 0.3317849040031433\n",
      "epoch 67, loss 0.32807981967926025\n",
      "epoch 68, loss 0.3244163691997528\n",
      "epoch 69, loss 0.3207933306694031\n",
      "epoch 70, loss 0.3172113597393036\n",
      "epoch 71, loss 0.3136690855026245\n",
      "epoch 72, loss 0.3101663887500763\n",
      "epoch 73, loss 0.3067026138305664\n",
      "epoch 74, loss 0.3032780885696411\n",
      "epoch 75, loss 0.2998912036418915\n",
      "epoch 76, loss 0.29654237627983093\n",
      "epoch 77, loss 0.293230801820755\n",
      "epoch 78, loss 0.2899564206600189\n",
      "epoch 79, loss 0.2867185175418854\n",
      "epoch 80, loss 0.28351691365242004\n",
      "epoch 81, loss 0.2803509533405304\n",
      "epoch 82, loss 0.2772201597690582\n",
      "epoch 83, loss 0.27412429451942444\n",
      "epoch 84, loss 0.27106350660324097\n",
      "epoch 85, loss 0.26803648471832275\n",
      "epoch 86, loss 0.26504355669021606\n",
      "epoch 87, loss 0.26208364963531494\n",
      "epoch 88, loss 0.25915706157684326\n",
      "epoch 89, loss 0.2562630772590637\n",
      "epoch 90, loss 0.2534015476703644\n",
      "epoch 91, loss 0.25057169795036316\n",
      "epoch 92, loss 0.2477736473083496\n",
      "epoch 93, loss 0.2450065165758133\n",
      "epoch 94, loss 0.24227066338062286\n",
      "epoch 95, loss 0.2395651787519455\n",
      "epoch 96, loss 0.23689021170139313\n",
      "epoch 97, loss 0.23424483835697174\n",
      "epoch 98, loss 0.2316291481256485\n",
      "epoch 99, loss 0.22904254496097565\n",
      "epoch 100, loss 0.22648490965366364\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta = \\theta - \\eta \\cdot \\nabla{\\theta}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
